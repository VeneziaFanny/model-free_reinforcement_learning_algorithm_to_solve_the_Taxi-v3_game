{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  500  possible states\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©er/initialiser l'environnement Taxi-v3\n",
    "env = gym.make(\"Taxi-v3\", render_mode=\"ansi\") \n",
    "# \"ansi\" permet dâ€™afficher lâ€™Ã©tat du jeu sous forme de texte / autre option : render_mode=\"rgb_array\"\n",
    "\n",
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'agent brute force\n",
    "\n",
    "Il suit une sÃ©quence fixe de mouvements sans tenir compte de son environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans l'episode 0\n",
      "Ã‰pisode 1: Reward total = -199994, Nombre d'Ã©tapes = 50000\n",
      "dans l'episode 1\n",
      "Ã‰pisode 2: Reward total = -199994, Nombre d'Ã©tapes = 50000\n",
      "dans l'episode 2\n",
      "Ã‰pisode 3: Reward total = -199994, Nombre d'Ã©tapes = 50000\n",
      "dans l'episode 3\n",
      "Ã‰pisode 4: Reward total = -50000, Nombre d'Ã©tapes = 50000\n",
      "dans l'episode 4\n",
      "Ã‰pisode 5: Reward total = -199994, Nombre d'Ã©tapes = 50000\n",
      "dans l'episode 5\n",
      "Ã‰pisode 6: Reward total = -199994, Nombre d'Ã©tapes = 50000\n",
      "dans l'episode 6\n",
      "Ã‰pisode 7: Reward total = -199994, Nombre d'Ã©tapes = 50000\n",
      "dans l'episode 7\n",
      "Ã‰pisode 8: Reward total = -199994, Nombre d'Ã©tapes = 50000\n",
      "dans l'episode 8\n",
      "Ã‰pisode 9: Reward total = -199994, Nombre d'Ã©tapes = 50000\n",
      "dans l'episode 9\n",
      "Ã‰pisode 10: Reward total = -199994, Nombre d'Ã©tapes = 50000\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10  # Nombre dâ€™Ã©pisodes Ã  exÃ©cuter\n",
    "total_rewards = []\n",
    "steps_per_episode = []\n",
    "\n",
    "# SÃ©quence fixe : HAUT â†’ DROITE â†’ BAS â†’ GAUCHE â†’ PRENDRE PASSAGER â†’ DÃ‰POSER\n",
    "fixed_sequence = [1, 2, 0, 3, 4, 5]\n",
    "max_steps = 50000 \n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    print(\"dans l'episode\", episode)\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        action = fixed_sequence[steps % len(fixed_sequence)]  # Boucle sur la sÃ©quence fixe\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    total_rewards.append(total_reward)\n",
    "    steps_per_episode.append(steps)\n",
    "\n",
    "    print(f\"Ã‰pisode {episode + 1}: Reward total = {total_reward}, Nombre d'Ã©tapes = {steps}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž **Ã‰valuation de l'agent Brute Force** ðŸ”Ž\n",
      "ðŸŽ¯ Moyenne des rÃ©compenses : -184994.60\n",
      "ðŸš¶â€â™‚ï¸ Moyenne des Ã©tapes : 50000.00\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” Ã‰valuation\n",
    "avg_reward = sum(total_rewards) / num_episodes\n",
    "avg_steps = sum(steps_per_episode) / num_episodes\n",
    "\n",
    "print(\"\\nðŸ”Ž **Ã‰valuation de l'agent Brute Force** ðŸ”Ž\")\n",
    "print(f\"ðŸŽ¯ Moyenne des rÃ©compenses : {avg_reward:.2f}\")\n",
    "print(f\"ðŸš¶â€â™‚ï¸ Moyenne des Ã©tapes : {avg_steps:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conlusions\n",
    "\n",
    "L'agent nâ€™adapte pas ses actions Ã  la situation.\n",
    "\n",
    "Il suit mÃ©caniqument une boucle de mouvements, ce qui entraÃ®ne un nombre Ã©levÃ© dâ€™Ã©tapes.\n",
    "\n",
    "Il risque de faire beaucoup de mouvements inutiles, ce qui baisse la rÃ©compense.\n",
    "\n",
    "TrÃ¨s faible reward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
