{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  500  possible states\n"
     ]
    }
   ],
   "source": [
    "# Créer/initialiser l'environnement Taxi-v3\n",
    "env = gym.make(\"Taxi-v3\", render_mode=\"ansi\") \n",
    "# \"ansi\" permet d’afficher l’état du jeu sous forme de texte / autre option : render_mode=\"rgb_array\"\n",
    "\n",
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'agent brute force\n",
    "\n",
    "Il suit une séquence fixe de mouvements sans tenir compte de son environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans l'episode 0\n",
      "Épisode 1: Reward total = -199994, Nombre d'étapes = 50000\n",
      "dans l'episode 1\n",
      "Épisode 2: Reward total = -199994, Nombre d'étapes = 50000\n",
      "dans l'episode 2\n",
      "Épisode 3: Reward total = -199994, Nombre d'étapes = 50000\n",
      "dans l'episode 3\n",
      "Épisode 4: Reward total = -50000, Nombre d'étapes = 50000\n",
      "dans l'episode 4\n",
      "Épisode 5: Reward total = -199994, Nombre d'étapes = 50000\n",
      "dans l'episode 5\n",
      "Épisode 6: Reward total = -199994, Nombre d'étapes = 50000\n",
      "dans l'episode 6\n",
      "Épisode 7: Reward total = -199994, Nombre d'étapes = 50000\n",
      "dans l'episode 7\n",
      "Épisode 8: Reward total = -199994, Nombre d'étapes = 50000\n",
      "dans l'episode 8\n",
      "Épisode 9: Reward total = -199994, Nombre d'étapes = 50000\n",
      "dans l'episode 9\n",
      "Épisode 10: Reward total = -199994, Nombre d'étapes = 50000\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10  # Nombre d’épisodes à exécuter\n",
    "total_rewards = []\n",
    "steps_per_episode = []\n",
    "\n",
    "# Séquence fixe : HAUT → DROITE → BAS → GAUCHE → PRENDRE PASSAGER → DÉPOSER\n",
    "fixed_sequence = [1, 2, 0, 3, 4, 5]\n",
    "max_steps = 50000 \n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    print(\"dans l'episode\", episode)\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        action = fixed_sequence[steps % len(fixed_sequence)]  # Boucle sur la séquence fixe\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    total_rewards.append(total_reward)\n",
    "    steps_per_episode.append(steps)\n",
    "\n",
    "    print(f\"Épisode {episode + 1}: Reward total = {total_reward}, Nombre d'étapes = {steps}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 **Évaluation de l'agent Brute Force** 🔎\n",
      "🎯 Moyenne des récompenses : -184994.60\n",
      "🚶‍♂️ Moyenne des étapes : 50000.00\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Évaluation\n",
    "avg_reward = sum(total_rewards) / num_episodes\n",
    "avg_steps = sum(steps_per_episode) / num_episodes\n",
    "\n",
    "print(\"\\n🔎 **Évaluation de l'agent Brute Force** 🔎\")\n",
    "print(f\"🎯 Moyenne des récompenses : {avg_reward:.2f}\")\n",
    "print(f\"🚶‍♂️ Moyenne des étapes : {avg_steps:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conlusions\n",
    "\n",
    "L'agent n’adapte pas ses actions à la situation.\n",
    "\n",
    "Il suit mécaniqument une boucle de mouvements, ce qui entraîne un nombre élevé d’étapes.\n",
    "\n",
    "Il risque de faire beaucoup de mouvements inutiles, ce qui baisse la récompense.\n",
    "\n",
    "Très faible reward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
